{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N1rVoYb1RC7"
      },
      "source": [
        "# Mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5KbvOLSPmcF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w46Nq_Qc8gda"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kigpFftyvAN1"
      },
      "source": [
        "#Ollama + Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, when the runtime is exceeded, the server from Ollama goes down, and Ollama must be restarted."
      ],
      "metadata": {
        "id": "daJeeaT-LVR1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMzS9Kr-sr29"
      },
      "outputs": [],
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "\n",
        "!pip install langchain langchain-core langchain_community -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBWRlaWxsubj"
      },
      "outputs": [],
      "source": [
        "%xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdkmMhhjwrjI"
      },
      "source": [
        "In the terminal, write down the texts in bold.\n",
        "\n",
        "**curl -fsSL https://ollama.com/install.sh | sh**\n",
        "\n",
        "**ollama serve & ollama pull llama3.1 & ollama pull llama3**\n",
        "\n",
        "We will use llama3.1 for the model, and llama3 for the embedding.\n",
        "\n",
        "- https://ollama.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCxvxpcXF1g2"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5huUi-mutW_-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "\n",
        "llm = Ollama(model=\"llama3.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45dgSD6T3Cyi"
      },
      "outputs": [],
      "source": [
        "!pip install ollama chromadb -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dryMA70L26gn"
      },
      "outputs": [],
      "source": [
        "import ollama\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the data in web pages"
      ],
      "metadata": {
        "id": "uT4boGUO25cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New medicines"
      ],
      "metadata": {
        "id": "CCgUDlx4OI52"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ykjKUTC2y3V"
      },
      "outputs": [],
      "source": [
        "# List of URLs to include in the RAG system\n",
        "urls = [\n",
        "    'https://www.ema.europa.eu/en/medicines/human/EPAR/anzupgo',\n",
        "    'https://www.ema.europa.eu/en/medicines/human/EPAR/balversa',\n",
        "    'https://www.ema.europa.eu/en/medicines/human/EPAR/adzynma'\n",
        "    # adzynma is a new orphan medicine.\n",
        "]\n",
        "\n",
        "# Load documents from all URLs\n",
        "all_docs = []\n",
        "for url in urls:\n",
        "    loader = WebBaseLoader(url)\n",
        "    docs = loader.load()\n",
        "    all_docs.extend(docs)  # Collect documents from all URLs\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(all_docs)\n",
        "\n",
        "# Create Ollama embeddings and vector store\n",
        "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufOoDuEyFjHE"
      },
      "outputs": [],
      "source": [
        "# Define the function to call the Ollama Llama3 model\n",
        "def ollama_llm(question, context):\n",
        "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
        "    response = ollama.chat(model='llama3.1', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
        "    return response['message']['content']\n",
        "\n",
        "# Define the RAG setup\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "def rag_chain(question):\n",
        "    retrieved_docs = retriever.invoke(question)\n",
        "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "    return ollama_llm(question, formatted_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aiD1S4lzpb9"
      },
      "outputs": [],
      "source": [
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(rag_chain(\"Extract the full therapeutic indication of each medicine and their patient group without summarization: \"))\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "AuINR8JV2yK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the model summarizes the indication."
      ],
      "metadata": {
        "id": "Nexd6BAz3Lwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Existing medicines"
      ],
      "metadata": {
        "id": "zvJIASOQOL9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gywnx2_AQ6Ni"
      },
      "outputs": [],
      "source": [
        "# List of URLs to include in the RAG system\n",
        "urls = [\n",
        "    'https://www.ema.europa.eu/en/medicines/human/variation/braftovi',\n",
        "    'https://www.ema.europa.eu/en/medicines/human/variation/arexvy',\n",
        "    'https://www.ema.europa.eu/en/medicines/human/variation/beyfortus',\n",
        "    'https://www.ema.europa.eu/en/medicines/human/variation/cresemba'\n",
        "]\n",
        "\n",
        "# Load documents from all URLs\n",
        "all_docs = []\n",
        "for url in urls:\n",
        "    loader = WebBaseLoader(url)\n",
        "    docs = loader.load()\n",
        "    all_docs.extend(docs)  # Collect documents from all URLs\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(all_docs)\n",
        "\n",
        "# Create Ollama embeddings and vector store\n",
        "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(rag_chain(\"What is the newly added indication for each medicine? The newly added or changed indication might be in bold or have strikethrough text.: \"))\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "UEPDwHczKNIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of URLs to include in the RAG system\n",
        "url = 'https://www.ema.europa.eu/en/medicines/human/variation/braftovi'\n",
        "#'https://www.ema.europa.eu/en/medicines/human/variation/arexvy'\n",
        "#'https://www.ema.europa.eu/en/medicines/human/variation/beyfortus'\n",
        "#'https://www.ema.europa.eu/en/medicines/human/variation/cresemba'\n",
        "\n",
        "loader = WebBaseLoader(url)\n",
        "doc = loader.load()\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(doc)\n",
        "\n",
        "# Create Ollama embeddings and vector store\n",
        "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
      ],
      "metadata": {
        "id": "0Y1jjyccMGpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(rag_chain(\"What is the newly added indication for this medicine? The newly added or changed indication might be in bold or have strikethrough text.: \"))\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "PfL_qvewMZjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All text on web pages is extracted as plain text and stored as vectors, ignoring bold or strikethrough formatting. This makes it difficult to extract new indications from those pages."
      ],
      "metadata": {
        "id": "8dBaEckQNSEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the data in .pdf files"
      ],
      "metadata": {
        "id": "sEv9ep_w3S8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWFBe1K0udvo"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf2 -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1UjXIduRHz"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "  with open(pdf_path, \"rb\") as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "      text += page.extract_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time"
      ],
      "metadata": {
        "id": "qKpYXYIQFMdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New medicines"
      ],
      "metadata": {
        "id": "6Tqcu5T2OVHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPGShORny5U3"
      },
      "outputs": [],
      "source": [
        "pdf_path = \"/content/drive/MyDrive/adzynma-new medicine-info.pdf\"\n",
        "pdf_text = extract_text_from_pdf(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(f\"Extract the full therapeutic indication of the medicine and its patient group without summarization: \\n\\n{pdf_text[:2000]}\")\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "aVrsAOds4U43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model summarizes the indication and cannot find this medicine's patient group."
      ],
      "metadata": {
        "id": "5300Cody5Lko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Existing medicines"
      ],
      "metadata": {
        "id": "p9qom7X5ObJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### From a single pdf file"
      ],
      "metadata": {
        "id": "8McmuU4YSbEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_pdf_path = \"/content/drive/MyDrive/alecensa-newly added indication.pdf\"\n",
        "one_pdf_text = extract_text_from_pdf(a_pdf_path)"
      ],
      "metadata": {
        "id": "HAH6xb7V8F6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(f\"Extract the newly added therapeutic indication of each medicine medicine and also its commission decision issued date : \\n\\n{one_pdf_text[:2000]}\")\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "NYJcQwbY8SIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_pdf_path = \"/content/drive/MyDrive/dupixent-newly added indication.pdf\"\n",
        "one_pdf_text = extract_text_from_pdf(a_pdf_path)"
      ],
      "metadata": {
        "id": "kw7yy-S5A4A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNd1yDQpy89U"
      },
      "outputs": [],
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(f\"Extract the newly added therapeutic indication of each medicine medicine and also its commission decision issued date : \\n\\n{one_pdf_text[:2000]}\")\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_pdf_path = \"/content/drive/MyDrive/arexvy-no new indication even though it has one.pdf\"\n",
        "one_pdf_text = extract_text_from_pdf(a_pdf_path)"
      ],
      "metadata": {
        "id": "b-qrPYepA8Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(f\"If a new therapeutic indication has been recently added, extract the newly added therapeutic indication and the date of the commission's decision. The newly added indication may begin with 'extension of indication...': \\n\\n{one_pdf_text[:2000]}\")\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "cLyIs44PA8Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_pdf_path = \"/content/drive/MyDrive/betmiga-no new indication even though it has one.pdf\"\n",
        "one_pdf_text = extract_text_from_pdf(a_pdf_path)"
      ],
      "metadata": {
        "id": "Is2tDzN-BqdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(f\"If a new therapeutic indication has been recently added, extract the newly added therapeutic indication and the date of the commission's decision. The newly added indication may begin with 'extension of indication...': \\n\\n{one_pdf_text[:2000]}\")\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "X8wzOUSmBqP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####From the list of pdf files"
      ],
      "metadata": {
        "id": "2-u6YrVFSeap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of .pdf files\n",
        "#pdfs_path = [\n",
        "#    '/content/drive/MyDrive/alecensa-newly added indication.pdf',\n",
        "#    '/content/drive/MyDrive/dupixent-newly added indication.pdf',\n",
        "#    '/content/drive/MyDrive/arexvy-no new indication even though it has one.pdf',\n",
        "#    '/content/drive/MyDrive/betmiga-no new indication even though it has one.pdf'\n",
        "#]\n",
        "\n",
        "# Function to extract the text from each pdf\n",
        "#def extract_texts_from_pdfs(pdfs_path):\n",
        "#    \"\"\"Extract text from a single PDF file.\"\"\"\n",
        "#    with open(pdfs_path, \"rb\") as file:\n",
        "#        reader = PyPDF2.PdfReader(file)\n",
        "#        text = \"\"\n",
        "#        for page in range(len(reader.pages)):\n",
        "#            text += reader.pages[page].extract_text()\n",
        "#    return text\n",
        "\n",
        "# Extract text from all PDFs\n",
        "#all_pdf_text = []\n",
        "#for pdf in pdfs_path:\n",
        "#    text = extract_texts_from_pdfs(pdf)\n",
        "#    all_pdf_text.append(text)"
      ],
      "metadata": {
        "id": "EiWgkSFb4-q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a single PDF file.\"\"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in range(len(reader.pages)):\n",
        "                text += reader.pages[page].extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# List of PDF files\n",
        "pdfs_path = [\n",
        "    '/content/drive/MyDrive/alecensa-newly added indication.pdf',\n",
        "    '/content/drive/MyDrive/dupixent-newly added indication.pdf',\n",
        "    '/content/drive/MyDrive/arexvy-no new indication even though it has one.pdf',\n",
        "    '/content/drive/MyDrive/betmiga-no new indication even though it has one.pdf'\n",
        "]\n",
        "\n",
        "# Extract text from all PDFs\n",
        "all_pdf_text = []\n",
        "for pdf in pdfs_path:\n",
        "    print(f\"Processing: {pdf}\")\n",
        "    text = extract_text_from_pdf(pdf)\n",
        "    print(f\"Length of extracted text: {len(text)} characters\")\n",
        "    all_pdf_text.append(text)\n",
        "\n",
        "# Verify the results\n",
        "for i, pdf_text in enumerate(all_pdf_text):\n",
        "    print(f\"\\n--- Text from PDF {i+1} ({pdfs_path[i]}) ---\")\n",
        "    print(pdf_text[:500], \"...\")"
      ],
      "metadata": {
        "id": "MtXkR385RoOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_start = time()\n",
        "response = llm.invoke(f\"If a new therapeutic indication has been recently added, extract the newly added therapeutic indication and the date of the commission's decision of each medicine. The newly added indication may begin with 'extension of indication...': \\n\\n{all_pdf_text[:2000]}\")\n",
        "print(response)\n",
        "time_end = time()\n",
        "print(f\"time taken: {round(time_end-time_start, 3)} sec.\")"
      ],
      "metadata": {
        "id": "Gy3ufOCy6jz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems the model cannot properly extract data from the text in merged text from each pdf file."
      ],
      "metadata": {
        "id": "Bg6izNGDSDyx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZfK86larOw8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YAw_p_0u4BS"
      },
      "source": [
        "#Hugging Face + Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It takes much more time compared to using Ollama, despite using a GPU.\n",
        "\n",
        "Also, it exceeds the GPU usage limit while importing the embedding model."
      ],
      "metadata": {
        "id": "wLjBT6Zvqx4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwan1geNuFXD"
      },
      "outputs": [],
      "source": [
        "!pip install \"transformers>=4.43.2\" --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain_community -qqq"
      ],
      "metadata": {
        "id": "pdbuAtoTs5oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "XkbjGcykrq93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -qqq"
      ],
      "metadata": {
        "id": "WiauNcRhuGmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "0xjKal0VrnPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
        "\n",
        "access_token = \"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\""
      ],
      "metadata": {
        "id": "oPBPreBCrVDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = transformers.pipeline(\"text-generation\", model=model_id, token=access_token, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "otAsVUmtrTtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "nbhk_Iv5tneX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.ema.europa.eu/en/medicines/human/EPAR/anzupgo'\n",
        "loader = WebBaseLoader(url)\n",
        "docs = loader.load()\n",
        "\n",
        "# Split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "E_ao19FJsStQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -qqq"
      ],
      "metadata": {
        "id": "DQZRS2f1u19G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "t--I6q2tunE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3.1-8B\"\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=model_name, encode_kwargs=encode_kwargs)"
      ],
      "metadata": {
        "id": "jMerFV_jupuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0TCBkA6nuZkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the retrieval system\n",
        "retriever = vectorstore.as_retriever()\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "Bxx2_BCztQyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}